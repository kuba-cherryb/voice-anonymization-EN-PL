{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "AI99Mt_YG9qX",
        "4QwzW49hHp6M",
        "EpGrm0hJzYyU",
        "Yckxsq7DHtHN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuba-cherryb/voice-anonymization-EN-PL/blob/main/voice_anonymization_PL_CMU_ARCTIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><font size=\"4\"><b>Speech technology 2024</b></font></center>\n",
        "<br />\n",
        "<center><font size=\"6\"><b><u>Project 2: Speech Anonymization.</u></b></font></center>\n",
        "<center>Jakub Czernecki, Wojciech Sabała, Bartosz Wąsik, 01/2025</center>"
      ],
      "metadata": {
        "id": "1gvWqJKOk6cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment setup"
      ],
      "metadata": {
        "id": "AI99Mt_YG9qX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Python modules"
      ],
      "metadata": {
        "id": "Lsc4VGdCIKhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/kuba-cherryb/voice-anonymization-EN-PL\n",
        "%cd voice-anonymization-EN-PL\n",
        "!pip install datasets\n",
        "!pip install speechbrain\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
        "from datasets import load_dataset, Audio\n",
        "import torch\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "from speechbrain.inference.speaker import EncoderClassifier\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import warnings\n",
        "import whisper\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "A1OW8My1HHG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pretrained models"
      ],
      "metadata": {
        "id": "Ra7faFIYJcU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Speech to Text - [Whisper](https://github.com/openai/whisper)"
      ],
      "metadata": {
        "id": "-Et2euWgJ15j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptor = whisper.load_model(\"turbo\")"
      ],
      "metadata": {
        "id": "om7jq_4fJ9QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###xvector extractor - [SpeechBrain Speaker Verification with xvector embeddings on Voxceleb](https://huggingface.co/speechbrain/spkrec-xvect-voxceleb)"
      ],
      "metadata": {
        "id": "y44fun9wKFVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")\n"
      ],
      "metadata": {
        "id": "e8usS54lK2Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthesizer - [SpeechT5](https://huggingface.co/blog/speecht5), [fine-tuned to Polish](kuba-cherryb/speecht5_tts_voxpopuli_pl_v4)"
      ],
      "metadata": {
        "id": "OgBrdpsCJfmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(\"kuba-cherryb/speecht5_tts_voxpopuli_pl_v4\")\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
      ],
      "metadata": {
        "id": "r5_uYkH0JXsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##xvector database - [CMU ARCTIC](https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors)"
      ],
      "metadata": {
        "id": "eAWOlbXQyynU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xvector_database = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "xvector_database = torch.tensor(xvector_database[\"xvector\"])"
      ],
      "metadata": {
        "id": "Sy7IqHCRzJTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis"
      ],
      "metadata": {
        "id": "4QwzW49hHp6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech to text"
      ],
      "metadata": {
        "id": "trnDo7NNG3t2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8drkG49XGzc6"
      },
      "outputs": [],
      "source": [
        "transcription = transcriptor.transcribe(\"resynthesis_pl.wav\")\n",
        "print(transcription[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text cleanup\n",
        "\n",
        "Tokenizer doesn't recognize foreign symbols and replaces them with `<unk>`. This creates a need to replace them with recognizable tokens. Additionally numbers are not recognized by the model, hence the replacement is necessary for them too."
      ],
      "metadata": {
        "id": "kE2vStZKl-NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replacements = [\n",
        "    ('ó', 'œ'),\n",
        "    ('ą', 'æ'),\n",
        "    ('ć', 'ê'),\n",
        "    ('ę', 'é'),\n",
        "    ('ł', 'X'),\n",
        "    ('ń', 'Q'),\n",
        "    ('ś', 'V'),\n",
        "    ('ź', 'q'),\n",
        "    ('ż', 'v'),\n",
        "    ('1', 'jeden'),\n",
        "    ('2', 'dwa'),\n",
        "    ('3', 'trzy'),\n",
        "    ('4', 'cztery'),\n",
        "    ('5', 'piéê'),\n",
        "    ('6', 'szeVê'),\n",
        "    ('7', 'siedem'),\n",
        "    ('8', 'osiem'),\n",
        "    ('9', 'dziewiéê'),\n",
        "    ('0', 'zero'),\n",
        "    ('%', 'procent'),\n",
        "]\n",
        "\n",
        "\n",
        "def cleanup_text(inputs):\n",
        "    for src, dst in replacements:\n",
        "        inputs[\"text\"] = inputs[\"text\"].lower().replace(src, dst)\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "a73Dww-1lxqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = cleanup_text(transcription)\n",
        "print(transcription[\"text\"])"
      ],
      "metadata": {
        "id": "sQSKNqs7nhp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##xvect_extraction"
      ],
      "metadata": {
        "id": "DxA0WFKWG6mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "signal, fs = torchaudio.load('resynthesis_pl.wav')\n",
        "extracted_xvector = classifier.encode_batch(signal[0]).squeeze(0)"
      ],
      "metadata": {
        "id": "YtMIxQXgHhTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Anonymization"
      ],
      "metadata": {
        "id": "EpGrm0hJzYyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anonymize(xvector):\n",
        "\n",
        "  #computing euclidian distance from each database speaker\n",
        "  #to determine the least similar speakers.\n",
        "  euclid_dist = torch.cdist(xvector_database, xvector,p=2)\n",
        "  ed_list = np.reshape(euclid_dist.tolist(), (-1))\n",
        "  least_similar_idx = ed_list.argsort()[-3:][::-1]\n",
        "\n",
        "  #averaging the least similar speakers to create anonymized\n",
        "  axv = []\n",
        "\n",
        "  for x in range(0,3):\n",
        "    axv.append(xvector_database[least_similar_idx[x]])\n",
        "\n",
        "  axv = np.mean(axv, axis=0)\n",
        "  anon_xvector1 = torch.tensor(axv).unsqueeze(0)\n",
        "\n",
        "\n",
        "  #max distance speaker\n",
        "  maxid = np.argmax(ed_list)\n",
        "  anxv3 = xvector_database[maxid]\n",
        "  anon_xvector2 = torch.tensor(anxv3).unsqueeze(0)\n",
        "\n",
        "\n",
        "  #determining random speakers to get a randomly distant, yet distant embedding\n",
        "  randidx = np.random.randint(0, len(xvector_database),1)\n",
        "  axv_rand = xvector_database[randidx]\n",
        "  anon_xvector3 = torch.tensor(axv_rand)\n",
        "\n",
        "  return anon_xvector1, anon_xvector2, anon_xvector3"
      ],
      "metadata": {
        "id": "wfUI0ijyzfs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anon_xvector1, anon_xvector2, anon_xvector3 = anonymize(xvector=extracted_xvector)"
      ],
      "metadata": {
        "id": "k0WIFEvvwjXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Synthesis"
      ],
      "metadata": {
        "id": "Yckxsq7DHtHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Original signal"
      ],
      "metadata": {
        "id": "BN3qJ4pWCRBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(signal, rate=16000)"
      ],
      "metadata": {
        "id": "MMFSBomVCTOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "gCsjjwg6HvIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Original speech resynthesis"
      ],
      "metadata": {
        "id": "uyZOtuR3Am-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=transcription[\"text\"], return_tensors=\"pt\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], extracted_xvector, vocoder=vocoder)\n",
        "Audio(speech, rate=16000)"
      ],
      "metadata": {
        "id": "zpKKyjb3H8kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Distance anonimization"
      ],
      "metadata": {
        "id": "YAWTKGMnAr7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=transcription[\"text\"], return_tensors=\"pt\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], anon_xvector1, vocoder=vocoder)\n",
        "Audio(speech, rate=16000)"
      ],
      "metadata": {
        "id": "XY2LORsUAzYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Max distance speaker"
      ],
      "metadata": {
        "id": "DeLqKWBpAwOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=transcription[\"text\"], return_tensors=\"pt\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], anon_xvector2, vocoder=vocoder)\n",
        "Audio(speech, rate=16000)"
      ],
      "metadata": {
        "id": "LHwMFBVlAz-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speaker randomization"
      ],
      "metadata": {
        "id": "Ql8IRw3rxiZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=transcription[\"text\"], return_tensors=\"pt\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], anon_xvector3, vocoder=vocoder)\n",
        "Audio(speech, rate=16000)"
      ],
      "metadata": {
        "id": "k_TeozhqxRU7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}